{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import pandas as pd\n",
    "from torch import optim \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms \n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random \n",
    "import timeit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the flow is:\n",
    "Transformer Encoder outputs (batch_size, num_patches + 1, embed_dim).\n",
    "\n",
    "You select the first token (CLS):\n",
    "```\n",
    "cls_token = output[:, 0, :]\n",
    "```\n",
    "→ shape (batch_size, embed_dim)\n",
    "\n",
    "Then apply:\n",
    "\n",
    "LayerNorm (normalize each embed_dim vector independently)\n",
    "\n",
    "Linear (map to num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the flow is:\n",
    "Transformer Encoder outputs (batch_size, num_patches + 1, embed_dim).\n",
    "\n",
    "You select the first token (CLS):\n",
    "```\n",
    "cls_token = output[:, 0, :]\n",
    "```\n",
    "→ shape (batch_size, embed_dim)\n",
    "\n",
    "Then apply:\n",
    "\n",
    "LayerNorm (normalize each embed_dim vector independently)\n",
    "\n",
    "Linear (map to num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the flow is:\n",
    "Transformer Encoder outputs (batch_size, num_patches + 1, embed_dim).\n",
    "\n",
    "You select the first token (CLS):\n",
    "```\n",
    "cls_token = output[:, 0, :]\n",
    "```\n",
    "→ shape (batch_size, embed_dim)\n",
    "\n",
    "Then apply:\n",
    "\n",
    "LayerNorm (normalize each embed_dim vector independently)\n",
    "\n",
    "Linear (map to num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the flow is:\n",
    "Transformer Encoder outputs (batch_size, num_patches + 1, embed_dim).\n",
    "\n",
    "You select the first token (CLS):\n",
    "```\n",
    "cls_token = output[:, 0, :]\n",
    "```\n",
    "→ shape (batch_size, embed_dim)\n",
    "\n",
    "Then apply:\n",
    "\n",
    "LayerNorm (normalize each embed_dim vector independently)\n",
    "\n",
    "Linear (map to num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT Architecture from the 16x16 words paper\n",
    "\n",
    "![vit_architecture](ViT_architecture.png)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Added Params (for training and testing)\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 512 \n",
    "EPOCHS = 40 ##why this high number? usually for transformers you do 1,2,3. \n",
    "\n",
    "##\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 10 #because MNIST\n",
    "PATCH_SIZE = 4 #we chose 4-> pixel length of 1 dimension\n",
    "IMAGE_SIZE = 28 #The MNIST dataset images are 28 × 28 pixels in size. (H,W) = (28, 28) \n",
    "IN_CHANNELS = 1 #MNIST only has 1 channel (Grayscale). Note: RGB would be 3 channels. \n",
    "NUM_HEADS = 8 #Within the transformer encoder there are attention heads- we choose 8 of them.                           \n",
    "DROPOUT = 0.001 \n",
    "HIDDEN_DIM = 768 #hidden dimentsion of MLP head for classification \n",
    "ADAM_WEIGHT_DECAY = 0 # paper uses 0.1, set it to 0 (defautl value)\n",
    "ADAM_BETAS = (0.9, 0.999) # again from paper. \n",
    "\n",
    "ACTIVATION = \"gelu\" #again use the same as the paper \n",
    "NUM_ENCODER = 4 #stack encoders on top of each other (architecture just shows one)\n",
    "\n",
    "\n",
    "##This is the input size to the patch embedding layer (aka flattening image into sequence of patches )\n",
    "EMBED_DIM = (PATCH_SIZE**2) * IN_CHANNELS # 16 -> basically the number of patches\n",
    "\n",
    "## Paper defines the below as: N =HW / P^2\n",
    "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2 # 49\n",
    "\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "device = \"cude\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OVERWRITE PARAMS TO TRAIN ON MY COMPUTER\n",
    "BATCH_SIZE = 512 #change to 256 if memory cant handle 512\n",
    "EPOCHS = 3\n",
    "NUM_HEADS = 4\n",
    "HIDDEN_DIM = 128\n",
    "NUM_ENCODER = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Check in on [CLS] Token and Positional Embeddings \n",
    "\n",
    "In ViT: \n",
    "- split image into patches and turn them into embeddings (1 patch = 1 embedding vector)\n",
    "- model pretends that the patches are a sequence of tokens, just like words in NLP models like BERT\n",
    "\n",
    "2 Important points : \n",
    "1) prepend a special [CLS] token (like \"classification token\") at the start of the sequence.\n",
    "2) add positional embeddings to every token (patches and the [CLS] token) so the model knows the order.\n",
    "\n",
    "# Example:\n",
    "1) After patch embedding, suppose we have: \n",
    "- 100 patches, where each patch is an embedding vector of size D (say, 768)\n",
    "- so our sequence has shape: (100,768)\n",
    "\n",
    "2) Create [CLS] token \n",
    "- Create a new learnable vector (randomly initialized) of size D, called the [CLS] token -> just another vector like a patch but it doesn't come from the image\n",
    "\n",
    "3) Prepend the [CLS] token\n",
    "- now sequence becomes: (1+100,768)\n",
    "- where First position: [CLS] token & Next positions: patch tokens\n",
    "\n",
    "4) Add Positional Embeddings \n",
    "- Transformers have no sense of order natively, so you add (element-wise) a positional embedding vector to each token\n",
    "- The [CLS] token gets a positional embedding for position 0.\n",
    "-  Patch tokens get positional embeddings for positions 1, 2, 3, ..., 100.\n",
    "- Now the model knows which patch is where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 50, 16])\n"
     ]
    }
   ],
   "source": [
    "# Creating CLS Tokens and merging with Positional Embeddings \n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, patch_size, num_patches, dropout, in_channels): \n",
    "        super().__init__()\n",
    "        \n",
    "        #function that divides images into patches\n",
    "        self.patcher = nn.Sequential(\n",
    "            # all Conv2d does is divide our image into patch sizes\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=embedding_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "            ), \n",
    "            nn.Flatten(start_dim=2)) #equivalent to nn.Flatten(start_dim=2, end_dim=-1) -> not a learnable layer (converts patched into sequence of vectors)\n",
    "        \n",
    "            #OUTPUT SHAPE: (batch_size, embedding_dim, num_patches) AKA the full sequence of patches\n",
    "            \n",
    "        \n",
    "        #---- CLS Token ---- \n",
    "     \n",
    "        #here we define the [CLS] token. nn.Parameter is a learnable tensor (its a single parameter not a full layer)\n",
    "        # Create a random tensor of shape (1, in_channels, embedding_dim), wrap it as a learnable parameter, and assign it as the CLS token\n",
    "        self.cls_token = nn.Parameter(torch.randn(size=(1,in_channels,embedding_dim)), requires_grad=True)\n",
    "        \n",
    "        \n",
    "        #---- Positional Embedding ---- \n",
    "        \n",
    "        \n",
    "        #positional embedding is a learnable parameter \n",
    "        self.position_embedding = nn.Parameter(torch.randn(size=(1,num_patches+1,embedding_dim)), requires_grad=True) #we add 1 to num_patches because we have the [CLS] token\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    \n",
    "    #after patching and flattening we have a tesnor of shape (batch_size, embedding_dim, num_patches) e.g., (32, 16, 49)\n",
    "    # x = x.permute(0, 2, 1) rearranges to (batch_size, num_patches, embedding_dim) e.g., (32, 49, 16)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x): \n",
    "        #here we expand the cls token so its not just the shape for 1 sample but for a batch of images\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1) #expand the cls token to the batch size. x.shape[0] is the batch size. -1, -1 tells expand function to keep original dimensions. \n",
    "        x = self.patcher(x).permute(0,2,1) # first patch x through patcher -> where nn.Conv2d: splits x into patches and embeds them, nn.Flatten(start_dim=2) converts into 1D sequence\n",
    "        \n",
    "        #1 axis for batches, 1 axis for sequence of patches, 1 axis for embedding dimension \n",
    "        x = torch.cat([cls_token, x], dim=1) #so we want to add the CLS token to the left of the patches\n",
    "        \n",
    "        #then we need to add the position tokens to each patch \n",
    "        x = self.position_embedding + x\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#always test model after you define it    \n",
    "model = PatchEmbedding(EMBED_DIM, PATCH_SIZE, NUM_PATCHES, DROPOUT, IN_CHANNELS).to(device)  \n",
    "x = torch.randn(512, 1, 28, 28).to(device)   #create dummy image of batch size 512, channels 1, and dimensions 28x28 \n",
    "print(model(x).shape) #expect (512, 50, 16) where batch size 512, 50 is number of tokens we feed transformer (correct because we have 49 patches + CLS token), 16 is size of patches (embedding dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: nn.Sequential is a convenience container in PyTorch.\n",
    "It lets you stack layers together in order, without writing a full forward() method manually.\n",
    "\n",
    "Instead of writing:\n",
    " ```python\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(10, 20)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "```\n",
    "You can do the same thing with nn.Sequential:\n",
    "\n",
    "```python\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 5)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on the layers:\n",
    "\n",
    "-  nn.Conv2d is a layer in PyTorch (torch.nn) used for applying a 2D convolution over an input, typically an image.\n",
    "    It slides filters (kernels) over a 2D input (like an image) and computes feature maps.\n",
    "- nn.Flatten() reshapes a tensor by flattening part of its dimensions into a single one.\n",
    "     Turns multi-dimensional data (like 2D or 3D feature maps) into a 1D vector per sample, usually before feeding it into fully connected (Linear) layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on cls_token:\n",
    "- shape is: 1 × in_channels × embedding_dim\n",
    "    - 1 -> Becaues we only have one CLS token per sample\n",
    "    - in_channels × embedding_dim -> to match the dimensions of the patch embedding vector because we add it to the sequence before feeding into the transformer.\n",
    "    - another note on the 1, it is a batch-size like-dimenssion, and we replace it with the batch size\n",
    "    \n",
    "    \n",
    "- why have it? \n",
    "    - CLS token = Learnable summary of the whole input.\n",
    "    - It acts as a summary token: after going through the transformer layers, the model will read the CLS token to decide the final class label.\n",
    "    - Think of it like a \"learnable prompt\" — the model writes its summary into it during training.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking the shapes:\n",
    "\n",
    "You start with an image of shape:\n",
    "(batch_size, in_channels, height, width) = (32, 1, 28, 28)\n",
    "\n",
    "\n",
    "then we apply patcher \n",
    "\n",
    "```\n",
    "self.patcher = nn.Sequential(\n",
    "    nn.Conv2d(in_channels, embedding_dim, patch_size, stride=patch_size),\n",
    "    nn.Flatten(start_dim=2)\n",
    ")\n",
    "\n",
    "```\n",
    "where nn.Conv2D divides the image into patches of size 4×4 pixels so we get: \n",
    "(batch_size, embedding_dim, height//patch_size, width//patch_size) = (32, 16, 7, 7)\n",
    "     where: \n",
    "     - 28 // 4 = 7 patches along height\n",
    "     - 28 // 4 = 7 patches along width\n",
    "     - 16 filters = 16 features per patch\n",
    "    \n",
    "Apply nn.Flatten(start_dim=2), which Flatten from dimension 2 onward:\n",
    "- Flatten (7,7) together into 49, so after flattening:\n",
    "- (batch_size, embedding_dim, num_patches) = (32, 16, 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick notes on below:\n",
    "- We implemented our encoder block using pytorch but we're meant to explicitely code it out -> I will do this after doing one full iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/korirogers/.pyenv/versions/3.10.4/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_patches, num_classes, patch_size, embed_dim, num_encoders, num_heads, hidden_dim, dropout, activation, in_channels):\n",
    "        super().__init__()\n",
    "        self.embeddings_block = PatchEmbedding(embed_dim, patch_size, num_patches, dropout, in_channels) #call the class we trained earlier -> this will give us the input to our encoder (divide image into patches and generate sequences)\n",
    "        \n",
    "        \n",
    "        #---- ENCODER ---- \n",
    "        #PyTorch version:\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, activation=activation, batch_first=True, norm_first=True) # we defined our images so that batch size comes first, so we should add: batch_first=True \n",
    "        \n",
    "        #above is only one encoder layer, we're stacking many encoder layers:\n",
    "        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n",
    "        \n",
    "        #---- MLP HEAD ---- \n",
    "        # The ViT typically uses only the [CLS] token for classification\n",
    "        \n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=embed_dim), #normalise each sequence with itself \n",
    "            nn.Linear(in_features=embed_dim, out_features=num_classes) #since we are doing classification, output features is number of classes (10 in our case)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings_block(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x = self.mlp_head(x[:, 0, :]) #we dont classify the whole embedding, instead we classify the CLS token in the beginning because its a learnable parameter and its meant to contain all the information the other parameters have\n",
    "        return x \n",
    "\n",
    "model = ViT(NUM_PATCHES, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODER, NUM_HEADS, HIDDEN_DIM, DROPOUT, ACTIVATION, IN_CHANNELS).to(device)  \n",
    "x = torch.randn(512, 1, 28, 28) #dummy image\n",
    "print(model(x).shape) #expect [512, 10] -> batch of 512 (512 images) for 10 classes -> returns a probability distribution over 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the flow is:\n",
    "Transformer Encoder outputs (batch_size, num_patches + 1, embed_dim).\n",
    "\n",
    "You select the first token (CLS):\n",
    "```\n",
    "cls_token = output[:, 0, :]\n",
    "```\n",
    "→ shape (batch_size, embed_dim)\n",
    "\n",
    "Then apply:\n",
    "\n",
    "LayerNorm (normalize each embed_dim vector independently)\n",
    "\n",
    "Linear (map to num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download MNIST dataset \n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "#Convert to Pandas dataframe \n",
    "# Train\n",
    "train_images = train_dataset.data.view(-1, 28*28).numpy()  # flatten images\n",
    "train_labels = train_dataset.targets.numpy()               # labels\n",
    "\n",
    "train_df = pd.DataFrame(train_images)\n",
    "train_df['label'] = train_labels  # add labels at the end\n",
    "\n",
    "# Test\n",
    "test_images = test_dataset.data.view(-1, 28*28).numpy()\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "test_df = pd.DataFrame(test_images)\n",
    "test_df['label'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  label  \n",
       "0    0      5  \n",
       "1    0      0  \n",
       "2    0      4  \n",
       "3    0      1  \n",
       "4    0      9  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  label  \n",
       "0    0      7  \n",
       "1    0      2  \n",
       "2    0      1  \n",
       "3    0      0  \n",
       "4    0      4  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train data into train and validation sets \n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=RANDOM_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need 3 separate dataset objects: train, val, test \n",
    "\n",
    "\n",
    "#---- TRAIN DATASET ---- \n",
    "\n",
    "class MNISTTrain(Dataset):\n",
    "#since this is a pytorch dataset we definitely need init, len, and getitem\n",
    "    def __init__(self, images, labels, indices):\n",
    "        self.images = images # the pixel data (e.g., from your train_df).\n",
    "        self.labels = labels # the ground truth labels (0–9).\n",
    "        self.indices = indices # which rows of the dataframe to use\n",
    "        \n",
    "        \n",
    "        #define the transformations we want to apply to the images\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(), #\tConvert tensor into a PIL Image so we can apply image transformations like rotation.\n",
    "            transforms.RandomRotation(15), #Randomly rotate the image by up to ±15 degrees \n",
    "            transforms.ToTensor(), # \tConvert back from PIL Image to a PyTorch Tensor\n",
    "            transforms.Normalize([0.5], [0.5]) #Normalize the image to have zero mean and unit variance\n",
    "        ])\n",
    "        #we apply random rotation to make the model more robust to rotation, and normalize the image to have zero mean and unit variance so that model converges faster\n",
    "        # All these transformations are automatically applied every time you load a sample from the dataset!\n",
    "        \n",
    "        #IMPORTANT: only apply transforms to the training set, not the validation or test set\n",
    "        \n",
    "    #when we call len it returns the number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    #when we call getitem it returns the sample at index idx\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28,28)).astype(np.uint8) #we reshape the image to 28x28 (MNIST images are 28x28) and convert to uint8 to be able to apply the transformations\n",
    "        label = self.labels[idx]\n",
    "        index = self.indices[idx]\n",
    "        \n",
    "        image = self.transforms(image) #we need to apply the transformations to the image\n",
    "\n",
    "        return {'image': image, 'label': label, 'index': index} #return a dictionary with the image, label, and index -> this is the train dataset object\n",
    "    \n",
    "    \n",
    "#---- VALIDATION DATASET ---- \n",
    "\n",
    "class MNISTVal(Dataset):\n",
    "    def __init__(self, images, labels, indices):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize([0.5], [0.5]) \n",
    "        ])\n",
    "    \n",
    "    #no transformations needed for validation set because we want the pure results of the dataset with augmentation -> however we can apply normalisation because at inference time, applying normalisation is fine. But applying augementation may harm results. \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28,28)).astype(np.uint8)\n",
    "        label = self.labels[idx]\n",
    "        index = self.indices[idx]\n",
    "        image = self.transforms(image) \n",
    "        \n",
    "        return {'image': image, 'label': label, 'index': index}\n",
    "        \n",
    "\n",
    "class MNISTTEst(Dataset):\n",
    "    def __init__(self, images, indices):\n",
    "        self.images = images\n",
    "        self.indices = indices\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize([0.5], [0.5]) \n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28,28)).astype(np.uint8)\n",
    "        index = self.indices[idx]\n",
    "        image = self.transforms(image) \n",
    "        \n",
    "        return {'image': image, 'index': index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5922,  0.9608,\n",
      "          -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,  0.9922,\n",
      "          -0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,  0.9922,\n",
      "          -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,\n",
      "           1.0000, -0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0039,\n",
      "           0.9922, -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3961,\n",
      "           0.9922, -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3961,\n",
      "           0.9922,  0.0980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3961,\n",
      "           0.9922,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.1216,\n",
      "           0.9922,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.2157,\n",
      "           0.9922,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,\n",
      "           0.9922,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,\n",
      "           0.9922, -0.0980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7020,\n",
      "           0.9373, -0.2078, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4824,\n",
      "           0.9765,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5373,\n",
      "           0.9686,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000,  0.7725,  0.5294, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000,  0.1294,  0.9686, -0.4980, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000,  0.1294,  0.9922, -0.3569, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000,  0.1294,  0.9922, -0.3569, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.5765,  0.5216, -0.6000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'label': 1, 'index': 50404}\n",
      "------------------------------\n",
      "6000\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.4667,  0.9216,  0.7804,\n",
      "          -0.6706, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.0039,  0.9294,  0.9765,\n",
      "           0.7725,  0.0118, -0.8353, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.0196,  0.9216,\n",
      "           0.9765,  0.9843,  0.5843, -0.4196, -0.8275, -0.8275, -0.9686,\n",
      "          -0.8275, -0.8275, -0.8980, -0.8275, -0.8275, -0.8275, -0.8275,\n",
      "          -0.9451, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5608,\n",
      "           0.3490,  0.9843,  0.9765,  0.9765,  0.9765,  0.9765,  0.4353,\n",
      "           0.9765,  0.9765,  0.7020,  0.9765,  0.9843,  0.9765,  0.9765,\n",
      "           0.2078, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000,  0.2941,  0.9765,  0.9765,  0.9765,  0.9765,  0.9843,\n",
      "           0.9765,  0.9765,  0.9765,  0.9765,  0.9843,  0.9765,  0.9765,\n",
      "           0.1373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.2314, -0.1686, -0.1686,  0.3176,\n",
      "           0.6549,  0.6549,  0.4510, -0.1686,  0.3725,  0.9843,  0.9843,\n",
      "          -0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.0353,  0.9765,  0.5765,\n",
      "          -0.8353, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.9216,  0.9765, -0.0118,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.7882,  0.9843,  0.9765, -0.5608,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.5216,  0.9843,  0.4275, -0.9686,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.4980,  0.9843,  1.0000, -0.1608, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.1216,  0.9765,  0.8745, -0.6706, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.4275,  0.9294,  0.9765, -0.5137, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.0039,  0.9765,  0.5608, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.7176,  0.7490,  0.9765, -0.6706, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           0.4980,  0.9843,  0.4902, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8824,\n",
      "           0.6549,  0.9765,  0.1373, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.2471,\n",
      "           0.9765,  0.9765,  0.4824, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7098,\n",
      "           0.9765,  0.9765,  0.2706, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.2941,\n",
      "           0.9765, -0.1922, -0.8902, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'label': 7, 'index': 12628}\n",
      "------------------------------\n",
      "10000\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3412,\n",
      "           0.4510,  0.2471,  0.1843, -0.5294, -0.7176, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7412,\n",
      "           0.9922,  0.9922,  0.9922,  0.9922,  0.8902,  0.5529,  0.5529,\n",
      "           0.5529,  0.5529,  0.5529,  0.5529,  0.5529,  0.5529,  0.3333,\n",
      "          -0.5922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4745,\n",
      "          -0.1059, -0.4353, -0.1059,  0.2784,  0.7804,  0.9922,  0.7647,\n",
      "           0.9922,  0.9922,  0.9922,  0.9608,  0.7961,  0.9922,  0.9922,\n",
      "           0.0980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.8667, -0.4824, -0.8902,\n",
      "          -0.4745, -0.4745, -0.4745, -0.5373, -0.8353,  0.8510,  0.9922,\n",
      "          -0.1686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,  0.9843,  0.6392,\n",
      "          -0.8588, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.8275,  0.8275,  1.0000, -0.3490,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.0118,  0.9922,  0.8667, -0.6549,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.5373,  0.9529,  0.9922, -0.5137, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.0431,  0.9922,  0.4667, -0.9608, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.9294,  0.6078,  0.9451, -0.5451, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.0118,  0.9922,  0.4275, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.4118,  0.9686,  0.8824, -0.5529, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8510,\n",
      "           0.7333,  0.9922,  0.3020, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765,  0.5922,\n",
      "           0.9922,  0.7176, -0.7255, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7020,  0.9922,\n",
      "           0.9922, -0.3961, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.7569,  0.7569,  0.9922,\n",
      "          -0.0980, -0.9922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0431,  0.9922,  0.9922,\n",
      "          -0.5922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.5216,  0.8980,  0.9922,  0.9922,\n",
      "          -0.5922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.0510,  0.9922,  0.9922,  0.7176,\n",
      "          -0.6863, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.0510,  0.9922,  0.6235, -0.8588,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'index': 0}\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets test our datasets (just like we tested our models)\n",
    "\n",
    "#plot samples from dataset\n",
    "plt.figure() #creates new empty figure for our plots \n",
    "f, axarr = plt.subplots(1, 3) #creates a 1x3 grid of subplots, f is the figure and axarr is an array of axes (subplots) -> one subplot for each train, test, val set. \n",
    "\n",
    "train_dataset = MNISTTrain(\n",
    "    images=train_df.iloc[:, :-1].values.astype(np.uint8), #we drop the last column (labels) and convert to uint8\n",
    "    labels=train_df['label'].values,\n",
    "    indices=train_df.index.values\n",
    ")\n",
    "\n",
    "#check if len works \n",
    "print(len(train_dataset))\n",
    "\n",
    "#check if getitem works \n",
    "print(train_dataset[0])\n",
    "\n",
    "#show image of data-set \n",
    "axarr[0].imshow(train_dataset[0]['image'].squeeze(), cmap='gray')\n",
    "#note, we know we can access via ['image'] cos we defined it in the dataset class above here: return {'image': image, 'label': label, 'index': index}\n",
    "\n",
    "axarr[0].set_title(f\"Train Image\")\n",
    "\n",
    "print(\"-\"*30)\n",
    "\n",
    "\n",
    "val_dataset = MNISTVal(\n",
    "    images=val_df.iloc[:, :-1].values.astype(np.uint8), \n",
    "    labels=val_df['label'].values,\n",
    "    indices=val_df.index.values\n",
    ")\n",
    "\n",
    "print(len(val_dataset))\n",
    "print(val_dataset[0])\n",
    "axarr[1].imshow(val_dataset[0]['image'].squeeze(), cmap='gray')\n",
    "axarr[1].set_title(f\"Val Image\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "\n",
    "#removed the labels from the test set\n",
    "test_dataset = MNISTTEst(\n",
    "    images=test_df.iloc[:, :-1].values.astype(np.uint8), \n",
    "    indices=test_df.index.values\n",
    ")\n",
    "\n",
    "\n",
    "print(len(test_dataset))\n",
    "print(test_dataset[0])\n",
    "\n",
    "axarr[2].imshow(test_dataset[0]['image'].squeeze(), cmap='gray')\n",
    "axarr[2].set_title(f\"Test Image\")\n",
    "\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define our Dataloaders\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [03:10<00:00,  1.79s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.58it/s]\n",
      " 33%|███▎      | 1/3 [03:13<06:27, 193.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 1: 2.3052\n",
      "Val loss EPOCH 1: 2.2863\n",
      "Train acc EPOCH 1: 0.1154\n",
      "Val acc EPOCH 1: 0.1747\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [03:11<00:00,  1.80s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.51it/s]\n",
      " 67%|██████▋   | 2/3 [06:28<03:14, 194.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 2: 2.0966\n",
      "Val loss EPOCH 2: 1.8554\n",
      "Train acc EPOCH 2: 0.2295\n",
      "Val acc EPOCH 2: 0.3292\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [05:19<00:00,  3.02s/it]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.80it/s]\n",
      "100%|██████████| 3/3 [11:53<00:00, 237.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train loss EPOCH 3: 1.6868\n",
      "Val loss EPOCH 3: 1.4273\n",
      "Train acc EPOCH 3: 0.4674\n",
      "Val acc EPOCH 3: 0.6115\n",
      "------------------------------\n",
      "Time taken: 713.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Now we get into training loop \n",
    "\n",
    "#define loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY, betas=ADAM_BETAS)\n",
    "\n",
    "#lets estimate the time it will take to train the model \n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "#we add 2 more parameters to the tqdm function: position and leave. \n",
    "for epoch in tqdm(range(EPOCHS), position =0, leave=True):\n",
    "    model.train() #take the model into train mode \n",
    "    \n",
    "    #we need to store train labels and predictions for a given epoch so we can calculate the loss and accuracy for that epoch so we initialise empty lists \n",
    "    train_labels = [] \n",
    "    train_preds = []\n",
    "    train_running_loss = 0.0 #store runnign losss which will start at 0\n",
    "     \n",
    "    #iterate through data loader \n",
    "    for idx, img_label in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "        #remember we return 'image' from dataset class and its a dataframe which is accessible like a dictionary\n",
    "        img = img_label['image'].float().to(device)\n",
    "        label = img_label['label'].type(torch.uint8).to(device) # remember MNIST labels are always integers between 0–9 (digits) so we store as int\n",
    "        y_pred = model(img)\n",
    "        \n",
    "        #recall the output shape is (batch_size, num_classes) aka ([512, 10]), which is a probability distribution over the 10 classes -> so we need to get the index of the highest probability\n",
    "        \n",
    "        \n",
    "        #to predict the label: \n",
    "        y_pred_label = torch.argmax(y_pred, dim=1) #take the column with the highest probability and select it -> dim 1 instead of 0 because we look across the rows of [512, 10] which is the classes\n",
    "        \n",
    "        #add to train labels. store to cpu when we can to avoid using up GPU memory \n",
    "        train_labels.extend(label.cpu().detach())\n",
    "        train_preds.extend(y_pred_label.cpu().detach())\n",
    "        \n",
    "        #3 lines below ensure that training is happening \n",
    "        \n",
    "        loss = criterion(y_pred, label) #calculate the loss -> returns a scalar tensor\n",
    "        optimizer.zero_grad() #zero the parameter gradients\n",
    "        loss.backward() #backpropagate the loss\n",
    "        optimizer.step() #update the model parameters\n",
    "        \n",
    "        #update the loss \n",
    "        train_running_loss += loss.item() #stores the loss for all batches in the epoch\n",
    "    \n",
    "    #now we update the train loss for the whole epoch     \n",
    "    train_loss = train_running_loss / len(train_dataloader) #stores the loss for 1 epoch -> average the loss over the number of batches in the epoch. so we have average loss per batch for 1 epoch. len(train_dataloader) = number of batches in the epoch\n",
    "    \n",
    "    \n",
    "    #calculate train accuracy (num of correct predictions / total num of predictions)\n",
    "    train_acc = sum(x == y for x, y in zip(train_labels, train_preds)) / len(train_labels)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    #take model into evaluation mode \n",
    "    model.eval()\n",
    "    val_labels = [] #store validation labels for a given epoch \n",
    "    val_preds = [] #store validation predictions for a given epoch \n",
    "    val_running_loss = 0.0 #store running loss for a given epoch \n",
    "    \n",
    "    #no need to track gradients in validation loop aka ensures no learning is happening in validation loop -> since we just want validation score from trained model \n",
    "    with torch.no_grad():\n",
    "        for idx, img_label in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "            img = img_label['image'].float().to(device)\n",
    "            label = img_label['label'].type(torch.uint8).to(device)\n",
    "            y_pred = model(img)\n",
    "            \n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "            \n",
    "            val_labels.extend(label.cpu().detach())\n",
    "            val_preds.extend(y_pred_label.cpu().detach())\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "            val_running_loss += loss.item()\n",
    "    val_loss = val_running_loss / len(val_dataloader)\n",
    "    val_acc = sum(x == y for x, y in zip(val_labels, val_preds)) / len(val_labels)\n",
    "\n",
    "            \n",
    "     #print as train happens \n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train loss EPOCH {epoch+1}: {train_loss:.4f}\")       \n",
    "    print(f\"Val loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
    "    print(f\"Train acc EPOCH {epoch+1}: {train_acc:.4f}\")\n",
    "    print(f\"Val acc EPOCH {epoch+1}: {val_acc:.4f}\")\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "stop = timeit.default_timer() \n",
    "print(f\"Time taken: {stop - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outer loop: \n",
    "- we loop over epochs\n",
    "\n",
    "Inner loop: \n",
    "- we loop over each batch from the dataloader \n",
    "\n",
    "\n",
    "You will see: e.g. 46/106 -> 106 is the number of batches. number of batches = dataset-size/batch-size = (54K) /512 =106 (round up) for train, 6k/512 = 12 (round up) for test. We always round up, last batch may be smaller but we still train on those samples. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
