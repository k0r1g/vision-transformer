


What are position embeddings? 




Videos on the 16x16 words paper:
https://www.youtube.com/watch?v=TrdevFK_am4&ab_channel=YannicKilcher






Learning embedding token: 
- adds a extra token which is the number of tokens 